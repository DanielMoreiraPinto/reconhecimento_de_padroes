{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHXIgcrGVzG8",
        "outputId": "b9e90105-5504-4a27-c9b1-5e92def7b7b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.pyplot._IonContext at 0x224bfcc6dc8>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "import re\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jawA44PlcK4b"
      },
      "source": [
        "BOTAR AQUI SUA PASTA DO NOTEBOOK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u3FVa380cKR0"
      },
      "outputs": [],
      "source": [
        "# pasta_do_notebook = '/content/drive/MyDrive/Blur_CLas'\n",
        "pasta_do_notebook = '.'\n",
        "os.chdir(pasta_do_notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "O37XW_9Mbt9e",
        "outputId": "1f528eae-77d4-4c09-cb60-f7a6b05eeb3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\daniel_moreira\\\\reconhecimento_de_padroes\\\\reconhecimento_de_padroes\\\\noisedetect'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to find reference and noisy images in a folder\n",
        "def find_images_in_folder(folder):\n",
        "    reference_image = None\n",
        "    noisy_image = None\n",
        "\n",
        "    # Iterate through files in the folder\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.lower().endswith(\".jpg\"):\n",
        "            file_path = os.path.join(folder, filename)\n",
        "\n",
        "            # Check if the image contains \"Reference\" or \"Noisy\"\n",
        "            if \"reference\" in filename.lower():\n",
        "                reference_image = cv.imread(file_path)\n",
        "            elif \"noisy\" in filename.lower():\n",
        "                noisy_image = cv.imread(file_path)\n",
        "\n",
        "            # Break if both images are found\n",
        "            if reference_image is not None and noisy_image is not None:\n",
        "                break\n",
        "\n",
        "    return reference_image, noisy_image\n",
        "\n",
        "# Main function to process folders\n",
        "def read_renoir(root_folders, num_images=0):\n",
        "    print('Reading RENOIR...')\n",
        "    targets, labels = [], []\n",
        "    for root_folder in os.listdir(root_folders):\n",
        "        root_folder_path = os.path.join(root_folders, root_folder)\n",
        "        print('Reading folder: ', root_folder)\n",
        "        for foldername in os.listdir(root_folder_path):\n",
        "            folder_path = os.path.join(root_folder_path, foldername)\n",
        "            if os.path.isdir(folder_path):\n",
        "                reference_image, noisy_image = find_images_in_folder(folder_path)\n",
        "                \n",
        "                targets.append(noisy_image)\n",
        "                labels.append(reference_image)\n",
        "                if num_images > 0 and len(targets) % num_images == 0:\n",
        "                    break\n",
        "    print('Reading complete.')\n",
        "    y = np.ones(len(targets))\n",
        "    np.concatenate((y, np.zeros(len(labels))))\n",
        "    np.concatenate((targets, labels))\n",
        "    return targets, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cjTzYf6UWrBW"
      },
      "outputs": [],
      "source": [
        "train_path = 'datasets/train'\n",
        "val_path = 'datasets/val'\n",
        "test_path = 'datasets/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading RENOIR...\n",
            "Reading folder:  Mi3_Aligned\n",
            "Reading folder:  S90_Aligned\n",
            "Reading folder:  T3i_Aligned\n",
            "Reading complete.\n",
            "Reading RENOIR...\n",
            "Reading folder:  Mi3_Aligned\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading folder:  S90_Aligned\n",
            "Reading folder:  T3i_Aligned\n",
            "Reading complete.\n",
            "Reading RENOIR...\n",
            "Reading folder:  Mi3_Aligned\n",
            "Reading folder:  S90_Aligned\n",
            "Reading folder:  T3i_Aligned\n",
            "Reading complete.\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = read_renoir(train_path, num_images=0)\n",
        "X_val, y_val = read_renoir(val_path, num_images=0)\n",
        "X_test, y_test = read_renoir(test_path, num_images=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYaCKO2PiHsf",
        "outputId": "50190797-54fb-4de2-cb6a-dbac3e7b5952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72\n",
            "24\n",
            "24\n",
            "[array([[[ 22,  64,  69],\n",
            "        [ 17,  61,  68],\n",
            "        [ 18,  63,  74],\n",
            "        ...,\n",
            "        [ 19,  37,  38],\n",
            "        [ 14,  38,  36],\n",
            "        [ 18,  48,  43]],\n",
            "\n",
            "       [[ 29,  65,  71],\n",
            "        [ 23,  60,  68],\n",
            "        [ 23,  61,  73],\n",
            "        ...,\n",
            "        [ 14,  28,  34],\n",
            "        [ 15,  36,  37],\n",
            "        [ 12,  36,  34]],\n",
            "\n",
            "       [[ 36,  59,  67],\n",
            "        [ 30,  55,  65],\n",
            "        [ 32,  58,  70],\n",
            "        ...,\n",
            "        [ 16,  25,  39],\n",
            "        [ 22,  32,  42],\n",
            "        [ 21,  33,  39]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 34,  51,  77],\n",
            "        [ 34,  55,  76],\n",
            "        [ 31,  59,  66],\n",
            "        ...,\n",
            "        [ 54,  92, 127],\n",
            "        [ 64, 100, 146],\n",
            "        [ 59,  96, 148]],\n",
            "\n",
            "       [[ 36,  65,  86],\n",
            "        [ 27,  61,  74],\n",
            "        [ 19,  59,  58],\n",
            "        ...,\n",
            "        [ 57, 105, 129],\n",
            "        [ 60, 111, 144],\n",
            "        [ 64, 116, 153]],\n",
            "\n",
            "       [[ 40,  76,  94],\n",
            "        [ 28,  67,  76],\n",
            "        [ 21,  67,  61],\n",
            "        ...,\n",
            "        [ 54, 107, 127],\n",
            "        [ 53, 110, 136],\n",
            "        [ 52, 112, 142]]], dtype=uint8), array([[[ 64,  71,  86],\n",
            "        [ 74,  64,  81],\n",
            "        [101,  56,  82],\n",
            "        ...,\n",
            "        [  3,  12,  25],\n",
            "        [  1,  10,  19],\n",
            "        [  5,  14,  18]],\n",
            "\n",
            "       [[ 64,  78,  90],\n",
            "        [ 70,  72,  83],\n",
            "        [ 79,  54,  68],\n",
            "        ...,\n",
            "        [  1,  13,  25],\n",
            "        [  4,  12,  25],\n",
            "        [  6,  15,  25]],\n",
            "\n",
            "       [[ 58,  89,  92],\n",
            "        [ 57,  83,  83],\n",
            "        [ 48,  64,  57],\n",
            "        ...,\n",
            "        [  2,  14,  26],\n",
            "        [  5,  14,  34],\n",
            "        [  6,  14,  37]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 83, 142, 161],\n",
            "        [ 83, 138, 159],\n",
            "        [ 98, 142, 166],\n",
            "        ...,\n",
            "        [157, 179, 250],\n",
            "        [151, 160, 227],\n",
            "        [193, 195, 255]],\n",
            "\n",
            "       [[ 69, 128, 144],\n",
            "        [ 71, 128, 143],\n",
            "        [ 74, 131, 140],\n",
            "        ...,\n",
            "        [167, 190, 255],\n",
            "        [152, 159, 239],\n",
            "        [179, 177, 255]],\n",
            "\n",
            "       [[ 76, 133, 148],\n",
            "        [ 77, 138, 148],\n",
            "        [ 65, 129, 130],\n",
            "        ...,\n",
            "        [146, 170, 246],\n",
            "        [157, 161, 249],\n",
            "        [171, 166, 255]]], dtype=uint8), array([[[  2,   9,  12],\n",
            "        [  0,   9,  12],\n",
            "        [  0,  10,  10],\n",
            "        ...,\n",
            "        [ 37,  49, 127],\n",
            "        [ 34,  47, 125],\n",
            "        [ 39,  55, 131]],\n",
            "\n",
            "       [[  0,   4,   7],\n",
            "        [  0,   6,   9],\n",
            "        [  0,   9,   9],\n",
            "        ...,\n",
            "        [ 40,  47, 126],\n",
            "        [ 39,  47, 124],\n",
            "        [ 44,  53, 127]],\n",
            "\n",
            "       [[  0,   3,   7],\n",
            "        [  2,   7,  10],\n",
            "        [  2,   9,  12],\n",
            "        ...,\n",
            "        [ 52,  52, 130],\n",
            "        [ 60,  52, 129],\n",
            "        [ 56,  46, 122]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[  2,   5,  13],\n",
            "        [  3,   5,  15],\n",
            "        [  1,   1,  17],\n",
            "        ...,\n",
            "        [255, 250, 255],\n",
            "        [255, 250, 255],\n",
            "        [255, 250, 255]],\n",
            "\n",
            "       [[  2,   8,   7],\n",
            "        [  1,   6,   7],\n",
            "        [  0,   3,   8],\n",
            "        ...,\n",
            "        [255, 250, 255],\n",
            "        [255, 250, 255],\n",
            "        [255, 250, 255]],\n",
            "\n",
            "       [[  0,   7,   2],\n",
            "        [  0,   4,   1],\n",
            "        [  0,   0,   1],\n",
            "        ...,\n",
            "        [255, 250, 255],\n",
            "        [255, 250, 255],\n",
            "        [255, 250, 255]]], dtype=uint8), array([[[ 54,  56,  90],\n",
            "        [ 57,  61,  85],\n",
            "        [ 74,  81,  84],\n",
            "        ...,\n",
            "        [ 97, 116, 143],\n",
            "        [ 80,  94, 122],\n",
            "        [ 98, 102, 131]],\n",
            "\n",
            "       [[ 84,  94, 118],\n",
            "        [ 60,  70,  87],\n",
            "        [ 60,  72,  74],\n",
            "        ...,\n",
            "        [ 88, 102, 125],\n",
            "        [ 86,  95, 122],\n",
            "        [ 93,  96, 124]],\n",
            "\n",
            "       [[ 52,  78,  85],\n",
            "        [ 54,  79,  83],\n",
            "        [ 65,  86,  84],\n",
            "        ...,\n",
            "        [ 78,  78,  96],\n",
            "        [ 84,  82, 104],\n",
            "        [ 82,  86, 110]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 27,  55,  72],\n",
            "        [ 46,  70,  92],\n",
            "        [ 50,  63,  95],\n",
            "        ...,\n",
            "        [ 21,  23, 135],\n",
            "        [ 26,  29, 138],\n",
            "        [ 30,  30, 138]],\n",
            "\n",
            "       [[ 41,  79,  97],\n",
            "        [ 40,  72,  95],\n",
            "        [ 52,  75, 107],\n",
            "        ...,\n",
            "        [ 29,  25, 138],\n",
            "        [ 25,  24, 134],\n",
            "        [ 24,  19, 128]],\n",
            "\n",
            "       [[ 19,  67,  85],\n",
            "        [ 31,  72,  97],\n",
            "        [ 49,  78, 115],\n",
            "        ...,\n",
            "        [ 20,  27, 130],\n",
            "        [ 18,  28, 129],\n",
            "        [ 16,  27, 125]]], dtype=uint8), array([[[  0,   0,  13],\n",
            "        [  0,   0,  14],\n",
            "        [  1,   2,  16],\n",
            "        ...,\n",
            "        [ 54,  25,  40],\n",
            "        [ 61,  20,  51],\n",
            "        [ 62,  18,  55]],\n",
            "\n",
            "       [[  0,   0,  11],\n",
            "        [  0,   1,  12],\n",
            "        [  1,   3,  14],\n",
            "        ...,\n",
            "        [ 55,  30,  40],\n",
            "        [ 55,  19,  43],\n",
            "        [ 56,  16,  44]],\n",
            "\n",
            "       [[  0,   0,  10],\n",
            "        [  0,   0,  10],\n",
            "        [  0,   2,  10],\n",
            "        ...,\n",
            "        [ 57,  36,  38],\n",
            "        [ 50,  25,  35],\n",
            "        [ 57,  29,  42]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 25,  29,  40],\n",
            "        [ 24,  29,  38],\n",
            "        [ 21,  32,  36],\n",
            "        ...,\n",
            "        [189, 151, 147],\n",
            "        [156, 151, 136],\n",
            "        [142, 155, 133]],\n",
            "\n",
            "       [[ 42,  31,  34],\n",
            "        [ 34,  27,  30],\n",
            "        [ 26,  25,  27],\n",
            "        ...,\n",
            "        [190, 149, 147],\n",
            "        [174, 151, 143],\n",
            "        [173, 159, 147]],\n",
            "\n",
            "       [[ 46,  28,  27],\n",
            "        [ 43,  29,  30],\n",
            "        [ 37,  31,  32],\n",
            "        ...,\n",
            "        [192, 148, 149],\n",
            "        [192, 160, 155],\n",
            "        [186, 158, 151]]], dtype=uint8)]\n",
            "24\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(X_val))\n",
        "print(X_val[:5])\n",
        "print(len(y_val))\n",
        "print(y_val[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ql6Mh92QXNl9"
      },
      "outputs": [],
      "source": [
        "# Function to create patches from an image with a specified patch size\n",
        "def split_image(image, patch_size=256, qtd=1):\n",
        "\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Calculate the number of rows and columns needed for patches\n",
        "    num_rows = math.ceil(height / patch_size)\n",
        "    num_cols = math.ceil(width / patch_size)\n",
        "\n",
        "    out_height = patch_size * num_rows\n",
        "    out_width = patch_size * num_cols\n",
        "\n",
        "    # Calculate the amount of padding needed\n",
        "    pad_height = out_height - height\n",
        "    pad_width = out_width - width\n",
        "\n",
        "    # Pad the image with zeros if necessary\n",
        "    if pad_height > 0 or pad_width > 0:\n",
        "        image = cv.copyMakeBorder(image, 0, pad_height, 0, pad_width, cv.BORDER_CONSTANT, value=0)\n",
        "\n",
        "    # Initialize an empty list to store the patches\n",
        "    patches = []\n",
        "\n",
        "    # Iterate through the image and extract patches\n",
        "    for y in range(0, out_height, patch_size):\n",
        "        for x in range(0, out_width, patch_size):\n",
        "            patch = image[y:y+patch_size, x:x+patch_size]\n",
        "            patches.append(patch)\n",
        "\n",
        "    if qtd < 1 and qtd > 0:\n",
        "        np.random.shuffle(patches)\n",
        "        patches = patches[:int(len(patches)*qtd)]\n",
        "\n",
        "    return np.array(patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "siGNQzC1nilO"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "\n",
        "# # Define your NumPy array of images\n",
        "# image_array = ex_patches\n",
        "\n",
        "# # Loop through each image in the array\n",
        "# for i in range(len(image_array)):\n",
        "#     # Convert the NumPy array to a PIL image\n",
        "#     image = Image.fromarray(image_array[i])\n",
        "\n",
        "#     # Display the image in the Jupyter notebook\n",
        "#     display(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0_8rSAr6jY2y"
      },
      "outputs": [],
      "source": [
        "def patchify(X, y, qtd_patches=1):\n",
        "    X_patches, y_patches = [], []\n",
        "    for i in range(len(X)):\n",
        "        patches = split_image(X[i], 256, qtd_patches)\n",
        "        X_patches.extend(patches)\n",
        "        for patch in patches:\n",
        "            if y[i] == 1:\n",
        "                y_patches.append(1)\n",
        "            else:\n",
        "                y_patches.append(0)\n",
        "    return np.array(X_patches), np.array(y_patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "An1BF-ttXXC9"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = patchify(X_train, y_train, 0.2)\n",
        "X_test, y_test = patchify(X_test, y_test, 0.2)\n",
        "X_val, y_val = patchify(X_val, y_val, 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists('datasets'):\n",
        "    os.makedirs('datasets')\n",
        "\n",
        "np.save('datasets/X_train.npy', X_train)\n",
        "np.save('datasets/y_train.npy', y_train)\n",
        "\n",
        "np.save('datasets/X_test.npy', X_test)\n",
        "np.save('datasets/y_test.npy', y_test)\n",
        "\n",
        "np.save('datasets/X_val.npy', X_val)\n",
        "np.save('datasets/y_val.npy', y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDc9CBqmdI5w",
        "outputId": "e69c8975-546d-48c5-e6d2-8381051b3609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2700\n",
            "928\n",
            "915\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(X_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_patches = np.load('datasets/X_train.npy')\n",
        "y_train_patches = np.load('datasets/y_train.npy')\n",
        "\n",
        "X_val_patches = np.load('datasets/X_val.npy')\n",
        "y_val_patches = np.load('datasets/y_val.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oAxB0xSpXb5l"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "if not os.path.exists('weights'):\n",
        "    os.mkdir('weights')\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath='weightscheckpoint_path.h5',\n",
        "    monitor='val_loss',  # Métrica para monitorar (pode ser 'val_loss' para perda de validação)\n",
        "    save_best_only=True,  # Salva apenas o melhor modelo\n",
        "    mode='min',  # 'max' se a métrica monitorada deve ser maximizada, 'min' se deve ser minimizada\n",
        "    verbose=1  # Exibe mensagens durante o salvamento do modelo\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZRY39S1XdPW",
        "outputId": "56873b01-6295-4f03-9163-7fa518479f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- unknown url type: https",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    547\u001b[0m         return self._call_chain(self.handle_open, 'unknown',\n\u001b[1;32m--> 548\u001b[1;33m                                 'unknown_open', req)\n\u001b[0m\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36munknown_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[0mtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unknown url type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mURLError\u001b[0m: <urlopen error unknown url type: https>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12008\\22432250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\site-packages\\keras\\applications\\densenet.py\u001b[0m in \u001b[0;36mDenseNet121\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m    332\u001b[0m   \u001b[1;34m\"\"\"Instantiates the Densenet121 architecture.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m   return DenseNet([6, 12, 24, 16], include_top, weights, input_tensor,\n\u001b[1;32m--> 334\u001b[1;33m                   input_shape, pooling, classes)\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\site-packages\\keras\\applications\\densenet.py\u001b[0m in \u001b[0;36mDenseNet\u001b[1;34m(blocks, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[0mDENSENET121_WEIGHT_PATH_NO_TOP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m             file_hash='30ee3e1110167f948a6b9946edeeb738')\n\u001b[0m\u001b[0;32m    305\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mblocks\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         weights_path = data_utils.get_file(\n",
            "\u001b[1;32md:\\daniel_moreira\\miniconda3\\envs\\rpt\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mException\u001b[0m: URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- unknown url type: https"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import certifi\n",
        "\n",
        "model = tf.keras.applications.densenet.DenseNet121(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(256, 256, 3)\n",
        ")\n",
        "\n",
        "top = GlobalAveragePooling2D()(model.output)\n",
        "top = Dense(1024, activation='relu')(top)\n",
        "top = Dense(1, activation='sigmoid')(top)\n",
        "model = Model(inputs=model.input, outputs=top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6crICgisol7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "def preprocess_data(X, y, shuffle=False):\n",
        "    # Shuffle the data if specified\n",
        "    X = X/255\n",
        "    if shuffle:\n",
        "        indices = np.arange(len(X))\n",
        "        np.random.shuffle(indices)\n",
        "        X = X[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whz0GVOWBrgl",
        "outputId": "1c2bd75e-194e-49fd-dd4b-676d9cc9bc41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1482, 256, 256, 3) (213, 256, 256, 3) (204, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = preprocess_data(X_train, y_train)\n",
        "X_test, y_test = preprocess_data(X_test, y_test)\n",
        "X_val, y_val = preprocess_data(X_val, y_val)\n",
        "print(X_train.shape, X_test.shape, X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy1MiuhABFqb"
      },
      "outputs": [],
      "source": [
        "# Convert NumPy arrays to TensorFlow tensors\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "\n",
        "# Create a tf.data.Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "\n",
        "# Batch, shuffle, and repeat the dataset\n",
        "batch_size = 16\n",
        "dataset = dataset.shuffle(buffer_size=len(X_train))\n",
        "dataset = dataset.batch(batch_size)\n",
        "# dataset = dataset.repeat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfjwFSPGXevH",
        "outputId": "c98688f1-ee9d-431c-9943-f3e9d47acba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.7274\n",
            "Epoch 1: val_loss improved from inf to 0.68267, saving model to checkpoint_path.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r93/93 [==============================] - 109s 386ms/step - loss: 0.6717 - accuracy: 0.7274 - val_loss: 0.6827 - val_accuracy: 0.7059\n",
            "Epoch 2/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.5322 - accuracy: 0.7713\n",
            "Epoch 2: val_loss did not improve from 0.68267\n",
            "93/93 [==============================] - 23s 243ms/step - loss: 0.5322 - accuracy: 0.7713 - val_loss: 0.6997 - val_accuracy: 0.7255\n",
            "Epoch 3/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.7632\n",
            "Epoch 3: val_loss did not improve from 0.68267\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.5241 - accuracy: 0.7632 - val_loss: 2.0463 - val_accuracy: 0.6176\n",
            "Epoch 4/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.7989\n",
            "Epoch 4: val_loss improved from 0.68267 to 0.54985, saving model to checkpoint_path.h5\n",
            "93/93 [==============================] - 26s 284ms/step - loss: 0.4708 - accuracy: 0.7989 - val_loss: 0.5499 - val_accuracy: 0.7696\n",
            "Epoch 5/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.7982\n",
            "Epoch 5: val_loss improved from 0.54985 to 0.49693, saving model to checkpoint_path.h5\n",
            "93/93 [==============================] - 27s 290ms/step - loss: 0.4612 - accuracy: 0.7982 - val_loss: 0.4969 - val_accuracy: 0.7745\n",
            "Epoch 6/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.8077\n",
            "Epoch 6: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 23s 249ms/step - loss: 0.4500 - accuracy: 0.8077 - val_loss: 0.5826 - val_accuracy: 0.7892\n",
            "Epoch 7/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8090\n",
            "Epoch 7: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 22s 241ms/step - loss: 0.4503 - accuracy: 0.8090 - val_loss: 0.5285 - val_accuracy: 0.7647\n",
            "Epoch 8/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4328 - accuracy: 0.8178\n",
            "Epoch 8: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 22s 240ms/step - loss: 0.4328 - accuracy: 0.8178 - val_loss: 0.5488 - val_accuracy: 0.7794\n",
            "Epoch 9/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.8347\n",
            "Epoch 9: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 23s 246ms/step - loss: 0.4210 - accuracy: 0.8347 - val_loss: 0.5746 - val_accuracy: 0.7892\n",
            "Epoch 10/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.8286\n",
            "Epoch 10: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 22s 238ms/step - loss: 0.4310 - accuracy: 0.8286 - val_loss: 0.6248 - val_accuracy: 0.7745\n",
            "Epoch 11/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.8178\n",
            "Epoch 11: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 23s 243ms/step - loss: 0.4225 - accuracy: 0.8178 - val_loss: 240.3231 - val_accuracy: 0.6716\n",
            "Epoch 12/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.8212\n",
            "Epoch 12: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 22s 240ms/step - loss: 0.4453 - accuracy: 0.8212 - val_loss: 2.9244 - val_accuracy: 0.6863\n",
            "Epoch 13/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.8192\n",
            "Epoch 13: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 24s 254ms/step - loss: 0.4340 - accuracy: 0.8192 - val_loss: 0.7532 - val_accuracy: 0.6667\n",
            "Epoch 14/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4200 - accuracy: 0.8273\n",
            "Epoch 14: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 22s 238ms/step - loss: 0.4200 - accuracy: 0.8273 - val_loss: 0.5980 - val_accuracy: 0.7451\n",
            "Epoch 15/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8192\n",
            "Epoch 15: val_loss did not improve from 0.49693\n",
            "93/93 [==============================] - 22s 240ms/step - loss: 0.4268 - accuracy: 0.8192 - val_loss: 0.5729 - val_accuracy: 0.7794\n",
            "Epoch 16/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8313\n",
            "Epoch 16: val_loss improved from 0.49693 to 0.49536, saving model to checkpoint_path.h5\n",
            "93/93 [==============================] - 26s 281ms/step - loss: 0.4140 - accuracy: 0.8313 - val_loss: 0.4954 - val_accuracy: 0.8039\n",
            "Epoch 17/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.8448\n",
            "Epoch 17: val_loss did not improve from 0.49536\n",
            "93/93 [==============================] - 23s 243ms/step - loss: 0.3820 - accuracy: 0.8448 - val_loss: 0.5232 - val_accuracy: 0.7990\n",
            "Epoch 18/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.8354\n",
            "Epoch 18: val_loss improved from 0.49536 to 0.48034, saving model to checkpoint_path.h5\n",
            "93/93 [==============================] - 29s 310ms/step - loss: 0.3953 - accuracy: 0.8354 - val_loss: 0.4803 - val_accuracy: 0.8137\n",
            "Epoch 19/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8428\n",
            "Epoch 19: val_loss did not improve from 0.48034\n",
            "93/93 [==============================] - 23s 242ms/step - loss: 0.3887 - accuracy: 0.8428 - val_loss: 0.5132 - val_accuracy: 0.8088\n",
            "Epoch 20/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.8320\n",
            "Epoch 20: val_loss did not improve from 0.48034\n",
            "93/93 [==============================] - 23s 252ms/step - loss: 0.4067 - accuracy: 0.8320 - val_loss: 0.5177 - val_accuracy: 0.7892\n",
            "Epoch 21/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.8428\n",
            "Epoch 21: val_loss did not improve from 0.48034\n",
            "93/93 [==============================] - 23s 252ms/step - loss: 0.3876 - accuracy: 0.8428 - val_loss: 0.6851 - val_accuracy: 0.7843\n",
            "Epoch 22/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8387\n",
            "Epoch 22: val_loss did not improve from 0.48034\n",
            "93/93 [==============================] - 22s 242ms/step - loss: 0.3946 - accuracy: 0.8387 - val_loss: 0.5559 - val_accuracy: 0.7696\n",
            "Epoch 23/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.8455\n",
            "Epoch 23: val_loss did not improve from 0.48034\n",
            "93/93 [==============================] - 22s 239ms/step - loss: 0.3788 - accuracy: 0.8455 - val_loss: 0.6449 - val_accuracy: 0.7598\n",
            "Epoch 24/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8617\n",
            "Epoch 24: val_loss did not improve from 0.48034\n",
            "93/93 [==============================] - 23s 247ms/step - loss: 0.3720 - accuracy: 0.8617 - val_loss: 0.6977 - val_accuracy: 0.7451\n",
            "Epoch 25/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8374\n",
            "Epoch 25: val_loss did not improve from 0.48034\n",
            "93/93 [==============================] - 23s 252ms/step - loss: 0.3887 - accuracy: 0.8374 - val_loss: 0.4953 - val_accuracy: 0.7794\n",
            "Epoch 26/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.8516\n",
            "Epoch 26: val_loss did not improve from 0.48034\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.3788 - accuracy: 0.8516 - val_loss: 0.8105 - val_accuracy: 0.7745\n",
            "Epoch 27/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3841 - accuracy: 0.8489\n",
            "Epoch 27: val_loss improved from 0.48034 to 0.47285, saving model to checkpoint_path.h5\n",
            "93/93 [==============================] - 30s 322ms/step - loss: 0.3841 - accuracy: 0.8489 - val_loss: 0.4729 - val_accuracy: 0.8235\n",
            "Epoch 28/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8536\n",
            "Epoch 28: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 22s 240ms/step - loss: 0.3582 - accuracy: 0.8536 - val_loss: 0.6533 - val_accuracy: 0.7696\n",
            "Epoch 29/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.8563\n",
            "Epoch 29: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 22s 242ms/step - loss: 0.3686 - accuracy: 0.8563 - val_loss: 0.5389 - val_accuracy: 0.7843\n",
            "Epoch 30/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8637\n",
            "Epoch 30: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 246ms/step - loss: 0.3501 - accuracy: 0.8637 - val_loss: 0.5360 - val_accuracy: 0.7843\n",
            "Epoch 31/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3246 - accuracy: 0.8725\n",
            "Epoch 31: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.3246 - accuracy: 0.8725 - val_loss: 0.5698 - val_accuracy: 0.7304\n",
            "Epoch 32/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8610\n",
            "Epoch 32: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.3513 - accuracy: 0.8610 - val_loss: 0.7889 - val_accuracy: 0.7990\n",
            "Epoch 33/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.8684\n",
            "Epoch 33: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 250ms/step - loss: 0.3488 - accuracy: 0.8684 - val_loss: 0.6359 - val_accuracy: 0.7696\n",
            "Epoch 34/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.8684\n",
            "Epoch 34: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 22s 241ms/step - loss: 0.3443 - accuracy: 0.8684 - val_loss: 0.6105 - val_accuracy: 0.8088\n",
            "Epoch 35/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.8704\n",
            "Epoch 35: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 249ms/step - loss: 0.3343 - accuracy: 0.8704 - val_loss: 0.5335 - val_accuracy: 0.7892\n",
            "Epoch 36/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3179 - accuracy: 0.8806\n",
            "Epoch 36: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.3179 - accuracy: 0.8806 - val_loss: 0.5230 - val_accuracy: 0.8039\n",
            "Epoch 37/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.8785\n",
            "Epoch 37: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 243ms/step - loss: 0.3202 - accuracy: 0.8785 - val_loss: 0.5869 - val_accuracy: 0.7794\n",
            "Epoch 38/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8752\n",
            "Epoch 38: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 244ms/step - loss: 0.3151 - accuracy: 0.8752 - val_loss: 0.6689 - val_accuracy: 0.7941\n",
            "Epoch 39/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.8907\n",
            "Epoch 39: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.2850 - accuracy: 0.8907 - val_loss: 0.5365 - val_accuracy: 0.7549\n",
            "Epoch 40/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.8839\n",
            "Epoch 40: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 22s 238ms/step - loss: 0.3049 - accuracy: 0.8839 - val_loss: 0.4930 - val_accuracy: 0.7892\n",
            "Epoch 41/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.8826\n",
            "Epoch 41: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 24s 258ms/step - loss: 0.3022 - accuracy: 0.8826 - val_loss: 0.5312 - val_accuracy: 0.7941\n",
            "Epoch 42/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.9022\n",
            "Epoch 42: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.2601 - accuracy: 0.9022 - val_loss: 0.6452 - val_accuracy: 0.8039\n",
            "Epoch 43/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.9089\n",
            "Epoch 43: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 242ms/step - loss: 0.2576 - accuracy: 0.9089 - val_loss: 0.9000 - val_accuracy: 0.7353\n",
            "Epoch 44/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.8711\n",
            "Epoch 44: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 22s 241ms/step - loss: 0.3266 - accuracy: 0.8711 - val_loss: 0.5662 - val_accuracy: 0.7696\n",
            "Epoch 45/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.9001\n",
            "Epoch 45: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 248ms/step - loss: 0.2509 - accuracy: 0.9001 - val_loss: 0.5914 - val_accuracy: 0.8186\n",
            "Epoch 46/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.9001\n",
            "Epoch 46: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.2846 - accuracy: 0.9001 - val_loss: 0.6051 - val_accuracy: 0.7696\n",
            "Epoch 47/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.9116\n",
            "Epoch 47: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 248ms/step - loss: 0.2550 - accuracy: 0.9116 - val_loss: 0.6349 - val_accuracy: 0.7794\n",
            "Epoch 48/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9150\n",
            "Epoch 48: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.2333 - accuracy: 0.9150 - val_loss: 0.8184 - val_accuracy: 0.7843\n",
            "Epoch 49/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.9089\n",
            "Epoch 49: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 22s 237ms/step - loss: 0.2459 - accuracy: 0.9089 - val_loss: 0.7764 - val_accuracy: 0.7941\n",
            "Epoch 50/50\n",
            "93/93 [==============================] - ETA: 0s - loss: 0.2519 - accuracy: 0.9028\n",
            "Epoch 50: val_loss did not improve from 0.47285\n",
            "93/93 [==============================] - 23s 245ms/step - loss: 0.2519 - accuracy: 0.9028 - val_loss: 0.6243 - val_accuracy: 0.7794\n",
            "7/7 [==============================] - 3s 421ms/step - loss: 0.5956 - accuracy: 0.7465\n",
            "Loss: 0.5956208109855652\n",
            "Accuracy: 0.7464788556098938\n",
            "Validation [0.6826650500297546, 0.6996835470199585, 2.046316623687744, 0.549851655960083, 0.49692994356155396, 0.5825701951980591, 0.5284667015075684, 0.5488384962081909, 0.5745561718940735, 0.6248442530632019, 240.3230743408203, 2.9243717193603516, 0.7532030940055847, 0.5980121493339539, 0.5729398131370544, 0.49535703659057617, 0.5231901407241821, 0.48034340143203735, 0.5132237672805786, 0.517723023891449, 0.6851339340209961, 0.5558930039405823, 0.6449159979820251, 0.6977002024650574, 0.4952525794506073, 0.8104555010795593, 0.4728529751300812, 0.6532707810401917, 0.5389490127563477, 0.5360113978385925, 0.5698085427284241, 0.7889329791069031, 0.6358718276023865, 0.6104860305786133, 0.5335047245025635, 0.5229739546775818, 0.5868566632270813, 0.6688812375068665, 0.5364896655082703, 0.49296993017196655, 0.5312120914459229, 0.6451621055603027, 0.8999968767166138, 0.5662405490875244, 0.5913730263710022, 0.6051233410835266, 0.6348655819892883, 0.8184036612510681, 0.7764419317245483, 0.6242716312408447]\n"
          ]
        }
      ],
      "source": [
        "# Compile o modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treine o modelo\n",
        "# r = model.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=50, callbacks=[checkpoint], batch_size = 8)\n",
        "r = model.fit(dataset, validation_data=(X_val,y_val), epochs=100, callbacks=[checkpoint])\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Exiba as métricas calculadas\n",
        "print(\"Loss:\", test_loss)\n",
        "print(\"Accuracy:\", test_accuracy)\n",
        "print(\"Validation\", r.history['val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5OxTop9Xgp2"
      },
      "outputs": [],
      "source": [
        "loss = r.history['loss']\n",
        "val_loss = r.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxjnm_5vXiIV"
      },
      "outputs": [],
      "source": [
        "acc1 = r.history['accuracy']\n",
        "val_acc1 = r.history['val_accuracy']\n",
        "plt.plot(epochs, acc1, 'y', label='Training acurácia')\n",
        "plt.plot(epochs, val_acc1, 'r', label='Validation acurácia')\n",
        "plt.title('Training and validation acurácia')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('acurácia')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_patches = np.load('datasets/X_test.npy')\n",
        "y_test_patches = np.load('datasets/y_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "213\n"
          ]
        }
      ],
      "source": [
        "print(len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "model = tf.keras.applications.densenet.DenseNet121(\n",
        "    include_top=False,\n",
        "    weights=None,\n",
        "    input_shape=(256, 256, 3)\n",
        ")\n",
        "\n",
        "top = GlobalAveragePooling2D()(model.output)\n",
        "top = Dense(1024, activation='relu')(top)\n",
        "top = Dense(1, activation='sigmoid')(top)\n",
        "model = Model(inputs=model.input, outputs=top)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "def preprocess_data(X, y, shuffle=False):\n",
        "    # Shuffle the data if specified\n",
        "    X = X/255\n",
        "    if shuffle:\n",
        "        indices = np.arange(len(X))\n",
        "        np.random.shuffle(indices)\n",
        "        X = X[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test, y_test = preprocess_data(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6667\n",
            "Precision: 0.6667\n",
            "Recall: 1.0000\n",
            "F1 Score: 0.8000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "model.load_weights(os.path.join(pasta_do_notebook, 'weights', 'checkpoint_path.h5'))\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_classes = np.round(y_pred)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
